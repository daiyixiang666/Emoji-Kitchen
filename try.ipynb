{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding=utf-8\n",
    "# Copyright 2023 The HuggingFace Inc. team. All rights reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "\n",
    "import argparse\n",
    "import gc\n",
    "import itertools\n",
    "import logging\n",
    "import math\n",
    "import os\n",
    "import shutil\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.checkpoint\n",
    "import transformers\n",
    "from accelerate import Accelerator\n",
    "from accelerate.logging import get_logger\n",
    "from accelerate.utils import (\n",
    "    DistributedDataParallelKwargs,\n",
    "    ProjectConfiguration,\n",
    "    set_seed,\n",
    ")\n",
    "from huggingface_hub import create_repo, upload_folder\n",
    "from huggingface_hub.utils import insecure_hashlib\n",
    "from packaging import version\n",
    "from PIL import Image\n",
    "from PIL.ImageOps import exif_transpose\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import AutoTokenizer, PretrainedConfig\n",
    "\n",
    "import diffusers\n",
    "from diffusers import (\n",
    "    AutoencoderKL,\n",
    "    DDPMScheduler,\n",
    "    DPMSolverMultistepScheduler,\n",
    "    StableDiffusionXLPipeline,\n",
    "    UNet2DConditionModel,\n",
    ")\n",
    "from diffusers.loaders import LoraLoaderMixin\n",
    "from diffusers.models.lora import LoRALinearLayer\n",
    "from diffusers.optimization import get_scheduler\n",
    "from diffusers.training_utils import compute_snr, unet_lora_state_dict\n",
    "from diffusers.utils import check_min_version, is_wandb_available\n",
    "from diffusers.utils.import_utils import is_xformers_available\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_prompt(tokenizer, prompt):\n",
    "    text_inputs = tokenizer(\n",
    "        prompt,\n",
    "        padding=\"max_length\",\n",
    "        max_length=tokenizer.model_max_length,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    text_input_ids = text_inputs.input_ids\n",
    "    return text_input_ids\n",
    "def encode_prompt(text_encoders, tokenizers, prompt, text_input_ids_list=None):\n",
    "    prompt_embeds_list = []\n",
    "\n",
    "    for i, text_encoder in enumerate(text_encoders):\n",
    "        if tokenizers is not None:\n",
    "            tokenizer = tokenizers[i]\n",
    "            text_input_ids = tokenize_prompt(tokenizer, prompt)\n",
    "        else:\n",
    "            assert text_input_ids_list is not None\n",
    "            text_input_ids = text_input_ids_list[i]\n",
    "\n",
    "        prompt_embeds = text_encoder(\n",
    "            text_input_ids.to(text_encoder.device),\n",
    "            output_hidden_states=True,\n",
    "        )\n",
    "\n",
    "        # We are only ALWAYS interested in the pooled output of the final text encoder\n",
    "        pooled_prompt_embeds = prompt_embeds[0]\n",
    "        print(pooled_prompt_embeds.shape)\n",
    "        prompt_embeds = prompt_embeds.hidden_states[-2]\n",
    "        bs_embed, seq_len, _ = prompt_embeds.shape\n",
    "        prompt_embeds = prompt_embeds.view(bs_embed, seq_len, -1)\n",
    "        prompt_embeds_list.append(prompt_embeds)\n",
    "\n",
    "    prompt_embeds = torch.concat(prompt_embeds_list, dim=-1)\n",
    "    pooled_prompt_embeds = pooled_prompt_embeds.view(bs_embed, -1)\n",
    "    return prompt_embeds, pooled_prompt_embeds\n",
    "\n",
    "def import_model_class_from_model_name_or_path(\n",
    "    pretrained_model_name_or_path: str, revision: str, subfolder: str = \"text_encoder\"\n",
    "):\n",
    "    text_encoder_config = PretrainedConfig.from_pretrained(\n",
    "        pretrained_model_name_or_path, subfolder=subfolder, revision=revision\n",
    "    )\n",
    "    model_class = text_encoder_config.architectures[0]\n",
    "\n",
    "    if model_class == \"CLIPTextModel\":\n",
    "        from transformers import CLIPTextModel\n",
    "\n",
    "        return CLIPTextModel\n",
    "    elif model_class == \"CLIPTextModelWithProjection\":\n",
    "        from transformers import CLIPTextModelWithProjection\n",
    "\n",
    "        return CLIPTextModelWithProjection\n",
    "    else:\n",
    "        raise ValueError(f\"{model_class} is not supported.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
      "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of CLIPTextModelWithProjection were not initialized from the model checkpoint at stabilityai/stable-diffusion-xl-base-1.0 and are newly initialized: ['text_projection.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "revision = None\n",
    "pretrained_model_name_or_path=\"stabilityai/stable-diffusion-xl-base-1.0\"\n",
    "tokenizer_one = AutoTokenizer.from_pretrained(\n",
    "    pretrained_model_name_or_path,\n",
    "    subfolder=\"tokenizer\",\n",
    "    revision=None,\n",
    "    use_fast=False,\n",
    ")\n",
    "tokenizer_two = AutoTokenizer.from_pretrained(\n",
    "    pretrained_model_name_or_path,\n",
    "    subfolder=\"tokenizer_2\",\n",
    "    revision=None,\n",
    "    use_fast=False,\n",
    ")\n",
    "text_encoder_cls_one = import_model_class_from_model_name_or_path(\n",
    "    pretrained_model_name_or_path, revision\n",
    ")\n",
    "text_encoder_cls_two = import_model_class_from_model_name_or_path(\n",
    "    pretrained_model_name_or_path, revision, subfolder=\"text_encoder_2\"\n",
    ")\n",
    "text_encoder_one = text_encoder_cls_one.from_pretrained(\n",
    "    pretrained_model_name_or_path,\n",
    "    subfolder=\"text_encoder\",\n",
    "    revision=revision,\n",
    ")\n",
    "text_encoder_two = text_encoder_cls_two.from_pretrained(\n",
    "    pretrained_model_name_or_path,\n",
    "    subfolder=\"text_encoder_2\",\n",
    "    revision=revision,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizers = [tokenizer_two]\n",
    "text_encoders = [text_encoder_two]\n",
    "\n",
    "def compute_text_embeddings(prompt, text_encoders, tokenizers):\n",
    "    with torch.no_grad():\n",
    "        prompt_embeds, pooled_prompt_embeds = encode_prompt(\n",
    "            text_encoders, tokenizers, prompt\n",
    "        )\n",
    "        prompt_embeds = prompt_embeds.to('cuda')\n",
    "        pooled_prompt_embeds = pooled_prompt_embeds.to('cuda')\n",
    "    return prompt_embeds, pooled_prompt_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 768])\n"
     ]
    }
   ],
   "source": [
    "out = compute_text_embeddings(\"hello I am good\", text_encoders, tokenizers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizers = [tokenizer_one, tokenizer_two]\n",
    "text_encoders = [text_encoder_one, text_encoder_two]\n",
    "prompt_embeds, pooled_prompt_embeds = encode_prompt(\n",
    "    text_encoders, tokenizers, prompt\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Dai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
