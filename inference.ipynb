{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub.repocard import RepoCard\n",
    "from diffusers import DiffusionPipeline\n",
    "import torch\n",
    "\n",
    "lora_model_id = \"lora-trained-xl_emoji_shit/scaler.pt\"\n",
    "card = RepoCard.load(lora_model_id)\n",
    "base_model_id = card.data.to_dict()[\"base_model\"]\n",
    "\n",
    "pipe = DiffusionPipeline.from_pretrained(base_model_id, torch_dtype=torch.float16)\n",
    "pipe = pipe.to(\"cuda\")\n",
    "pipe.load_lora_weights(lora_model_id)\n",
    "image = pipe(\"A picture of a sks dog in a bucket\", num_inference_steps=25).images[0]\n",
    "image.save(\"sks_dog.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import create_repo, hf_hub_download, upload_folder\n",
    "\n",
    "repo_id = create_repo(\n",
    "    repo_id=\"lora-trained-xl_emoji_shit\", exist_ok=True, token=\"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\"\n",
    ").repo_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionXLPipeline\n",
    "lora_path = \"lora-trained-xl_emoji_angry_sks\"\n",
    "pipeline = StableDiffusionXLPipeline.from_pretrained(\"stabilityai/stable-diffusion-xl-base-1.0\")\n",
    "pipeline.load_lora_weights(lora_path)\n",
    "pipeline.to(device=\"cuda\", dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"a photo of dyxa emoji best quality\" \n",
    "image = pipeline(prompt=prompt, num_inference_steps=50).images[0]\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Optional, Dict\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "import torch\n",
    "from safetensors import safe_open\n",
    "from diffusers import UNet2DConditionModel\n",
    "from diffusers.loaders.lora import LORA_WEIGHT_NAME_SAFE\n",
    "from ziplora_pytorch.utils import (\n",
    "    get_lora_weights,\n",
    "    merge_lora_weights,\n",
    "    initialize_ziplora_layer,\n",
    "    unet_ziplora_state_dict,\n",
    "    ziplora_set_forward_type,\n",
    "    ziplora_compute_mergers_similarity,\n",
    "    insert_ziplora_to_unet,\n",
    ")\n",
    "\n",
    "def get_lora_weights(\n",
    "    lora_name_or_path: str, subfolder: Optional[str] = None, **kwargs\n",
    ") -> Dict[str, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        lora_name_or_path (str): huggingface repo id or folder path of lora weights\n",
    "        subfolder (Optional[str], optional): sub folder. Defaults to None.\n",
    "    \"\"\"\n",
    "    if os.path.exists(lora_name_or_path):\n",
    "        if subfolder is not None:\n",
    "            lora_name_or_path = os.path.join(lora_name_or_path, subfolder)\n",
    "        if os.path.isdir(lora_name_or_path):\n",
    "            lora_name_or_path = os.path.join(lora_name_or_path, LORA_WEIGHT_NAME_SAFE)\n",
    "    else:\n",
    "        lora_name_or_path = hf_hub_download(\n",
    "            repo_id=lora_name_or_path,\n",
    "            filename=LORA_WEIGHT_NAME_SAFE,\n",
    "            subfolder=subfolder,\n",
    "            **kwargs,\n",
    "        )\n",
    "    assert lora_name_or_path.endswith(\n",
    "        \".safetensors\"\n",
    "    ), \"Currently only safetensors is supported\"\n",
    "    tensors = {}\n",
    "    with safe_open(lora_name_or_path, framework=\"pt\", device=\"cpu\") as f:\n",
    "        for key in f.keys():\n",
    "            tensors[key] = f.get_tensor(key)\n",
    "    return tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_weights = get_lora_weights(\"lora-trained-xl_emoji_angry_dyxa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = UNet2DConditionModel.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-xl-base-1.0\", subfolder=\"unet\", revision=None\n",
    ")\n",
    "unet.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_lora_weights(\n",
    "    tensors: torch.Tensor, key: str, prefix: str = \"unet.\"\n",
    ") -> Dict[str, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        tensors (torch.Tensor): state dict of lora weights\n",
    "        key (str): target attn layer's key\n",
    "        prefix (str, optional): prefix for state dict. Defaults to \"unet.unet.\".\n",
    "    \"\"\"\n",
    "    target_key = prefix + key\n",
    "    out = {}\n",
    "    for part in [\"to_q\", \"to_k\", \"to_v\", \"to_out.0\"]:\n",
    "        down_key = target_key + f\".{part}.lora.down.weight\"\n",
    "        up_key = target_key + f\".{part}.lora.up.weight\"\n",
    "        merged_weight = tensors[up_key] @ tensors[down_key]\n",
    "        out[part] = merged_weight\n",
    "    return out\n",
    "unet_lora_parameters = []\n",
    "for attn_processor_name, attn_processor in unet.attn_processors.items():\n",
    "    # Parse the attention module.\n",
    "    attn_module = unet\n",
    "    for n in attn_processor_name.split(\".\")[:-1]:\n",
    "        attn_module = getattr(attn_module, n)\n",
    "    # Get prepared for ziplora\n",
    "    attn_name = \".\".join(attn_processor_name.split(\".\")[:-1])\n",
    "    merged_lora_weights_dict = merge_lora_weights(lora_weights, attn_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6134da816b9006f7cccb9b2bc66c70ce7b8d0ad67eca1f63c89772a9690ebdbd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
